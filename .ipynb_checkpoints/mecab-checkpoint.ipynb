{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence text file -> pos tagging\n",
    "# output = sentence\\n token_id\\t token\\t pos\\w\n",
    "\n",
    "import MeCab\n",
    "m = MeCab.Tagger()\n",
    "\n",
    "\n",
    "# 한 문장 -> (형태소, 형태소 종류) 분석 결과 리스트\n",
    "def parse_mecab_str(tagger, text):\n",
    "    out = tagger.parse(text).split('\\n')\n",
    "    tups = []\n",
    "    for i in out[:-2] :# EOS 제외\n",
    "        name,tag = i.split('\\t')[0],i.split('\\t')[1].split(',')[0]\n",
    "        tups.append((name,tag))\n",
    "    return tups\n",
    "\n",
    "# 한 토큰 당 형태소 분석 결과물 저장\n",
    "# ex: [('이것', 'NP'),('은', 'JX')] -> [('이것은','이것 은', 'NP+JX')] \n",
    "def pos_to_token(poses, text): \n",
    "    tokens = text.split(' ')\n",
    "    poslist = []\n",
    "    taglist = []\n",
    "    for tok in tokens:\n",
    "        pos_set = ''\n",
    "        tag_set = ''\n",
    "        while len(poses)> 0:\n",
    "            pos, tag = poses.pop(0)\n",
    "            if pos in tok:\n",
    "                pos_set +=' '+pos\n",
    "                tag_set +='+'+tag\n",
    "            else:\n",
    "                poses.insert(0,(pos,tag))\n",
    "                break\n",
    "        poslist.append(pos_set.strip())\n",
    "        if tag_set[0]=='+':\n",
    "            tag_set = tag_set[1:]\n",
    "        taglist.append(tag_set)\n",
    "    return tokens, poslist, taglist\n",
    "\n",
    "# read .txt file and convert to .tsv file which has klue-dp's input form\n",
    "def make_file(file):\n",
    "    f = open(file, 'rt', encoding='UTF8')\n",
    "    g = open(file.replace('.txt','.tsv'), 'w')\n",
    "    head = '## 칼럼명 : INDEX\tWORD_FORM\tLEMMA\tPOS\tHEAD\tDEPREL\\n'\n",
    "    gid = 0\n",
    "    gids = '## klue-dp-eval_%06d\t'\n",
    "    g.write(head)\n",
    "\n",
    "    writes =[]\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        text = line.strip()\n",
    "        poses = parse_mecab_str(m, text)\n",
    "        tokens, poslist, taglist = pos_to_token(poses, text)\n",
    "        g.write(gids % gid + text+'\\n') # write gid with original sentence\n",
    "        for tid, tok in enumerate(tokens):\n",
    "            ws ='{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(tid+1, tok, poslist[tid], taglist[tid], 0, 'NP')\n",
    "            g.write(ws)\n",
    "        gid +=1\n",
    "        g.write('\\n')\n",
    "    f.close()\n",
    "    g.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    make_file(sys.argv[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
